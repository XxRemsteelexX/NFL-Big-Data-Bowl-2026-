{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Big Data Bowl 2026 - Ensemble Prediction\n",
    "\n",
    "**Best Overall: 0.540-0.541 Public LB**\n",
    "\n",
    "This notebook demonstrates how to combine multiple models into an ensemble for best performance.\n",
    "\n",
    "**4-Model Ensemble Components**:\n",
    "| Model | Public LB | Weight |\n",
    "|-------|-----------|--------|\n",
    "| ST Transformer (6L) | 0.547 | 0.2517 |\n",
    "| Multiscale CNN | 0.548 | 0.2517 |\n",
    "| GRU (Seed 27) | 0.557 | 0.2476 |\n",
    "| Position-Specific ST | 0.553 | 0.2490 |\n",
    "\n",
    "**Contents**:\n",
    "1. Ensemble Strategy Overview\n",
    "2. Weight Calculation\n",
    "3. Model Loading\n",
    "4. Ensemble Prediction\n",
    "5. Test-Time Augmentation\n",
    "6. Complete Ensemble Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:20:03.812777Z",
     "iopub.status.busy": "2026-01-15T18:20:03.812672Z",
     "iopub.status.idle": "2026-01-15T18:20:04.630365Z",
     "shell.execute_reply": "2026-01-15T18:20:04.630085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Imports ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ensemble Strategy\n",
    "\n",
    "**Why Ensemble?**\n",
    "- Different architectures capture different patterns\n",
    "- Reduces variance and overfitting\n",
    "- Typical improvement: 0.01-0.02 on leaderboard\n",
    "\n",
    "**Best Practices**:\n",
    "1. Use diverse architectures (Transformer, GRU, CNN)\n",
    "2. Use different seeds for same architecture\n",
    "3. Weight by inverse LB score (better = higher weight)\n",
    "4. Apply TTA to each model before averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:20:04.673833Z",
     "iopub.status.busy": "2026-01-15T18:20:04.673679Z",
     "iopub.status.idle": "2026-01-15T18:20:04.676477Z",
     "shell.execute_reply": "2026-01-15T18:20:04.676270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble models:\n",
      "  6-Layer ST Transformer: 0.547 LB\n",
      "  Multiscale CNN + 2L ST: 0.548 LB\n",
      "  GRU (Seed 27): 0.557 LB\n",
      "  Position-Specific ST: 0.553 LB\n"
     ]
    }
   ],
   "source": [
    "# Model configurations from actual submissions\n",
    "ENSEMBLE_CONFIG = {\n",
    "    'st_transformer': {\n",
    "        'name': '6-Layer ST Transformer',\n",
    "        'public_lb': 0.547,\n",
    "        'cv_score': 0.0750,\n",
    "        'n_folds': 20,\n",
    "        'kaggle_dataset': '6layer-seed700-flip-only',\n",
    "    },\n",
    "    'multiscale_cnn': {\n",
    "        'name': 'Multiscale CNN + 2L ST',\n",
    "        'public_lb': 0.548,\n",
    "        'cv_score': 0.0751,\n",
    "        'n_folds': 20,\n",
    "        'kaggle_dataset': 'st-multiscale-cnn-w10-20fold',\n",
    "    },\n",
    "    'gru_seed27': {\n",
    "        'name': 'GRU (Seed 27)',\n",
    "        'public_lb': 0.557,\n",
    "        'cv_score': 0.0798,\n",
    "        'n_folds': 20,\n",
    "        'kaggle_dataset': 'gru-w9-seed27-20fold',\n",
    "    },\n",
    "    'position_st': {\n",
    "        'name': 'Position-Specific ST',\n",
    "        'public_lb': 0.553,\n",
    "        'cv_score': 0.0750,\n",
    "        'n_folds': 5,  # per position\n",
    "        'kaggle_dataset': 'nfl-bdb-2026-position-st-combined',\n",
    "    },\n",
    "}\n",
    "\n",
    "print('Ensemble models:')\n",
    "for key, cfg in ENSEMBLE_CONFIG.items():\n",
    "    print(f\"  {cfg['name']}: {cfg['public_lb']} LB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Weight Calculation\n",
    "\n",
    "Calculate ensemble weights based on inverse LB scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:20:04.677394Z",
     "iopub.status.busy": "2026-01-15T18:20:04.677312Z",
     "iopub.status.idle": "2026-01-15T18:20:04.681884Z",
     "shell.execute_reply": "2026-01-15T18:20:04.681689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Weights:\n",
      "  st_transformer: 0.2519\n",
      "  multiscale_cnn: 0.2515\n",
      "  gru_seed27: 0.2474\n",
      "  position_st: 0.2492\n",
      "\n",
      "Total: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def calculate_weights(lb_scores: Dict[str, float]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate ensemble weights from LB scores.\n",
    "    Lower LB score = higher weight (inverse weighting)\n",
    "    \n",
    "    Args:\n",
    "        lb_scores: Dict of model_name -> public LB score\n",
    "    \n",
    "    Returns:\n",
    "        Dict of model_name -> normalized weight\n",
    "    \"\"\"\n",
    "    # Inverse scores (lower is better)\n",
    "    inv_scores = {k: 1.0 / v for k, v in lb_scores.items()}\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    total = sum(inv_scores.values())\n",
    "    weights = {k: v / total for k, v in inv_scores.items()}\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Calculate weights for our ensemble\n",
    "lb_scores = {k: v['public_lb'] for k, v in ENSEMBLE_CONFIG.items()}\n",
    "WEIGHTS = calculate_weights(lb_scores)\n",
    "\n",
    "print('Ensemble Weights:')\n",
    "for model, weight in WEIGHTS.items():\n",
    "    print(f\"  {model}: {weight:.4f}\")\n",
    "print(f\"\\nTotal: {sum(WEIGHTS.values()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensemble Predictor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:20:04.682826Z",
     "iopub.status.busy": "2026-01-15T18:20:04.682746Z",
     "iopub.status.idle": "2026-01-15T18:20:04.696677Z",
     "shell.execute_reply": "2026-01-15T18:20:04.696474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsemblePredictor class defined\n"
     ]
    }
   ],
   "source": [
    "class EnsemblePredictor:\n",
    "    \"\"\"\n",
    "    Ensemble multiple trajectory prediction models.\n",
    "    \n",
    "    Supports:\n",
    "    - Multiple model types with different architectures\n",
    "    - Weighted averaging based on LB scores\n",
    "    - Test-Time Augmentation (TTA)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_configs: Dict, weights: Dict, device='cuda'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_configs: Dict with model configurations\n",
    "            weights: Dict with model weights\n",
    "            device: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        self.configs = model_configs\n",
    "        self.weights = weights\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        # Model storage\n",
    "        self.models = {}  # model_name -> List[fold_models]\n",
    "        self.scalers = {}  # model_name -> List[fold_scalers]\n",
    "        \n",
    "        self.loaded = False\n",
    "    \n",
    "    def load_models(self, base_dir: Path):\n",
    "        \"\"\"\n",
    "        Load all ensemble models from directory.\n",
    "        \n",
    "        Expected structure:\n",
    "        base_dir/\n",
    "            st_transformer/\n",
    "                model_fold1.pt, scaler_fold1.pkl, ...\n",
    "            gru_seed27/\n",
    "                model_fold1.pt, scaler_fold1.pkl, ...\n",
    "            ...\n",
    "        \"\"\"\n",
    "        base_dir = Path(base_dir)\n",
    "        \n",
    "        for model_name, cfg in self.configs.items():\n",
    "            model_dir = base_dir / model_name\n",
    "            if not model_dir.exists():\n",
    "                print(f\"Warning: {model_name} directory not found\")\n",
    "                continue\n",
    "            \n",
    "            models = []\n",
    "            scalers = []\n",
    "            \n",
    "            for fold in range(1, cfg['n_folds'] + 1):\n",
    "                model_path = model_dir / f'model_fold{fold}.pt'\n",
    "                scaler_path = model_dir / f'scaler_fold{fold}.pkl'\n",
    "                \n",
    "                if model_path.exists():\n",
    "                    # Load based on model type\n",
    "                    model = self._create_model(model_name)\n",
    "                    state = torch.load(model_path, map_location='cpu')\n",
    "                    model.load_state_dict(state)\n",
    "                    model.to(self.device)\n",
    "                    model.eval()\n",
    "                    models.append(model)\n",
    "                    \n",
    "                    if scaler_path.exists():\n",
    "                        with open(scaler_path, 'rb') as f:\n",
    "                            scalers.append(pickle.load(f))\n",
    "            \n",
    "            self.models[model_name] = models\n",
    "            self.scalers[model_name] = scalers\n",
    "            print(f\"Loaded {model_name}: {len(models)} folds\")\n",
    "        \n",
    "        self.loaded = True\n",
    "    \n",
    "    def _create_model(self, model_name: str):\n",
    "        \"\"\"Create model instance based on type.\"\"\"\n",
    "        # Import appropriate model class based on name\n",
    "        # This is a placeholder - implement based on your model classes\n",
    "        raise NotImplementedError(\"Implement model creation for each type\")\n",
    "    \n",
    "    def predict(self, sequences: List[np.ndarray], use_tta: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Run ensemble prediction.\n",
    "        \n",
    "        Args:\n",
    "            sequences: List of (window_size, n_features) arrays\n",
    "            use_tta: Whether to use test-time augmentation\n",
    "        \n",
    "        Returns:\n",
    "            (dx, dy) ensemble predictions\n",
    "        \"\"\"\n",
    "        all_dx = []\n",
    "        all_dy = []\n",
    "        all_weights = []\n",
    "        \n",
    "        for model_name, models in self.models.items():\n",
    "            if not models:\n",
    "                continue\n",
    "            \n",
    "            scalers = self.scalers.get(model_name, [None] * len(models))\n",
    "            weight = self.weights.get(model_name, 1.0 / len(self.models))\n",
    "            \n",
    "            # Average predictions across folds\n",
    "            fold_preds = []\n",
    "            for model, scaler in zip(models, scalers):\n",
    "                # Scale inputs\n",
    "                if scaler:\n",
    "                    X = [scaler.transform(s) for s in sequences]\n",
    "                else:\n",
    "                    X = sequences\n",
    "                \n",
    "                X_tensor = torch.tensor(np.stack(X).astype(np.float32)).to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    preds = model(X_tensor).cpu().numpy()\n",
    "                \n",
    "                if use_tta:\n",
    "                    # Add TTA prediction\n",
    "                    X_flip = [self._horizontal_flip(s) for s in X]\n",
    "                    X_flip_tensor = torch.tensor(np.stack(X_flip).astype(np.float32)).to(self.device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        preds_flip = model(X_flip_tensor).cpu().numpy()\n",
    "                    \n",
    "                    # Average (flip dy back)\n",
    "                    preds[:, :, 0] = (preds[:, :, 0] + preds_flip[:, :, 0]) / 2\n",
    "                    preds[:, :, 1] = (preds[:, :, 1] - preds_flip[:, :, 1]) / 2\n",
    "                \n",
    "                fold_preds.append(preds)\n",
    "            \n",
    "            # Average across folds\n",
    "            model_preds = np.mean(fold_preds, axis=0)\n",
    "            all_dx.append(model_preds[:, :, 0] * weight)\n",
    "            all_dy.append(model_preds[:, :, 1] * weight)\n",
    "            all_weights.append(weight)\n",
    "        \n",
    "        # Weighted sum\n",
    "        total_weight = sum(all_weights)\n",
    "        ens_dx = sum(all_dx) / total_weight\n",
    "        ens_dy = sum(all_dy) / total_weight\n",
    "        \n",
    "        return ens_dx, ens_dy\n",
    "    \n",
    "    def _horizontal_flip(self, seq: np.ndarray, y_idx: int = 1) -> np.ndarray:\n",
    "        \"\"\"Horizontal flip for TTA.\"\"\"\n",
    "        flipped = seq.copy()\n",
    "        flipped[:, y_idx] = 53.3 - flipped[:, y_idx]\n",
    "        return flipped\n",
    "\n",
    "print('EnsemblePredictor class defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple Ensemble Function\n",
    "\n",
    "For quick use without the full class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:20:04.697671Z",
     "iopub.status.busy": "2026-01-15T18:20:04.697581Z",
     "iopub.status.idle": "2026-01-15T18:20:04.704670Z",
     "shell.execute_reply": "2026-01-15T18:20:04.704009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example ensemble:\n",
      "  Input shapes: (100, 94, 2), (100, 94, 2), (100, 94, 2)\n",
      "  Output shape: (100, 94, 2)\n"
     ]
    }
   ],
   "source": [
    "def simple_ensemble(predictions: List[np.ndarray], weights: List[float] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple weighted average of predictions.\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of (N, horizon, 2) prediction arrays\n",
    "        weights: Optional weights (defaults to equal)\n",
    "    \n",
    "    Returns:\n",
    "        (N, horizon, 2) ensemble predictions\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0 / len(predictions)] * len(predictions)\n",
    "    \n",
    "    # Normalize weights\n",
    "    weights = np.array(weights)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    # Weighted average\n",
    "    ensemble = np.zeros_like(predictions[0])\n",
    "    for pred, w in zip(predictions, weights):\n",
    "        ensemble += pred * w\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "# Example usage\n",
    "print('Example ensemble:')\n",
    "pred1 = np.random.randn(100, 94, 2)  # Model 1\n",
    "pred2 = np.random.randn(100, 94, 2)  # Model 2\n",
    "pred3 = np.random.randn(100, 94, 2)  # Model 3\n",
    "\n",
    "weights = [0.4, 0.35, 0.25]  # Based on LB scores\n",
    "ensemble_pred = simple_ensemble([pred1, pred2, pred3], weights)\n",
    "\n",
    "print(f'  Input shapes: {pred1.shape}, {pred2.shape}, {pred3.shape}')\n",
    "print(f'  Output shape: {ensemble_pred.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:20:04.705864Z",
     "iopub.status.busy": "2026-01-15T18:20:04.705776Z",
     "iopub.status.idle": "2026-01-15T18:20:04.709320Z",
     "shell.execute_reply": "2026-01-15T18:20:04.709150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Summary:\n",
      "               Model  Public LB CV Score In Ensemble\n",
      " ST Transformer (6L)      0.547    0.075         Yes\n",
      "      Multiscale CNN      0.548   0.0751         Yes\n",
      "Position-Specific ST      0.553    0.075         Yes\n",
      "       GRU (Seed 27)      0.557   0.0798         Yes\n",
      "   Geometric Network      0.559   0.0828        Top5\n",
      "    4-Model Ensemble      0.541      N/A        BEST\n",
      "\n",
      " Key Insights:\n",
      "  - Ensemble improves ~0.006 over best single model\n",
      "  - Diverse architectures contribute most\n",
      "  - TTA adds ~0.005-0.010 improvement\n",
      "  - Weight by inverse LB score works well\n"
     ]
    }
   ],
   "source": [
    "# Results from actual submissions\n",
    "results = pd.DataFrame([\n",
    "    {'Model': 'ST Transformer (6L)', 'Public LB': 0.547, 'CV Score': 0.0750, 'In Ensemble': 'Yes'},\n",
    "    {'Model': 'Multiscale CNN', 'Public LB': 0.548, 'CV Score': 0.0751, 'In Ensemble': 'Yes'},\n",
    "    {'Model': 'Position-Specific ST', 'Public LB': 0.553, 'CV Score': 0.0750, 'In Ensemble': 'Yes'},\n",
    "    {'Model': 'GRU (Seed 27)', 'Public LB': 0.557, 'CV Score': 0.0798, 'In Ensemble': 'Yes'},\n",
    "    {'Model': 'Geometric Network', 'Public LB': 0.559, 'CV Score': 0.0828, 'In Ensemble': 'Top5'},\n",
    "    {'Model': '4-Model Ensemble', 'Public LB': 0.541, 'CV Score': 'N/A', 'In Ensemble': 'BEST'},\n",
    "])\n",
    "\n",
    "print('Model Performance Summary:')\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "print('\\n Key Insights:')\n",
    "print('  - Ensemble improves ~0.006 over best single model')\n",
    "print('  - Diverse architectures contribute most')\n",
    "print('  - TTA adds ~0.005-0.010 improvement')\n",
    "print('  - Weight by inverse LB score works well')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Ensemble Best Practices**:\n",
    "\n",
    "1. **Diversity** - Use different architectures (Transformer, GRU, CNN)\n",
    "2. **Seeds** - Train same architecture with multiple seeds\n",
    "3. **Weighting** - Inverse LB score weighting\n",
    "4. **TTA** - Horizontal flip averaging\n",
    "5. **Folds** - Average across all CV folds\n",
    "\n",
    "**Final Ensemble (0.541 LB)**:\n",
    "- ST Transformer (25.17%)\n",
    "- Multiscale CNN (25.17%)\n",
    "- GRU Seed 27 (24.76%)\n",
    "- Position-Specific ST (24.90%)\n",
    "\n",
    "**Code Notebooks**:\n",
    "- `02_st_transformer_training.ipynb` - ST Transformer\n",
    "- `05_gnn_geometric_training.ipynb` - GNN/Geometric\n",
    "- `06_gru_training.ipynb` - GRU\n",
    "- `07_kaggle_submission.ipynb` - Submission format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
